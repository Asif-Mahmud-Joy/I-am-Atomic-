const axios = require("axios");
const fs = require("fs-extra");
const gtts = require("gtts");
const path = require("path");

module.exports = {
  config: {
    name: "bardv2",
    version: "2.0",
    usePrefix: true,
    hasPermission: 0,
    credits: "ğŸ© ğŒğ«.ğ’ğ¦ğ¨ğ¤ğğ² â€¢ ğ€ğ¬ğ¢ğŸ ğŒğšğ¡ğ¦ğ®ğ ğŸŒ ",
    description: "Bard AI with image-to-text and voice reply",
    commandCategory: "ai",
    usages: "{pn} <question or image reply>",
    cooldowns: 5,
    guide: {
      en: "Reply to an image or type your question directly",
      bn: "à¦›à¦¬à¦¿à¦° à¦°à¦¿à¦ªà§à¦²à¦¾à¦‡ à¦¦à¦¿à¦¨ à¦…à¦¥à¦¬à¦¾ à¦¸à¦°à¦¾à¦¸à¦°à¦¿ à¦ªà§à¦°à¦¶à§à¦¨ à¦²à¦¿à¦–à§à¦¨"
    }
  },

  langs: {
    en: {
      processing: "Searching for an answer, please wait...",
      noInput: "Please provide a question or reply to an image.",
      imgError: "âŒ Couldn't extract text from the image. Try a clearer one.",
      voiceError: "âŒ Error generating voice response.",
      apiError: "âŒ Something went wrong while fetching data."
    },
    bn: {
      processing: "à¦‰à¦¤à§à¦¤à¦° à¦–à¦¾à¦à¦œà¦¾ à¦¹à¦šà§à¦›à§‡, à¦…à¦¨à§à¦—à§à¦°à¦¹ à¦•à¦°à§‡ à¦…à¦ªà§‡à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨...",
      noInput: "à¦ªà§à¦°à¦¶à§à¦¨ à¦²à¦¿à¦–à§à¦¨ à¦…à¦¥à¦¬à¦¾ à¦•à§‹à¦¨à§‹ à¦›à¦¬à¦¿à¦° à¦°à¦¿à¦ªà§à¦²à¦¾à¦‡ à¦¦à¦¿à¦¨à¥¤",
      imgError: "âŒ à¦›à¦¬à¦¿à¦° à¦¥à§‡à¦•à§‡ à¦²à§‡à¦–à¦¾ à¦ªà§œà¦¾ à¦¯à¦¾à§Ÿà¦¨à¦¿, à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦° à¦›à¦¬à¦¿ à¦¦à¦¿à¦¨à¥¤",
      voiceError: "âŒ à¦­à§Ÿà§‡à¦¸ à¦°à§‡à¦¸à¦ªà¦¨à§à¦¸ à¦¤à§à¦°à¦¿à¦°à¦¿ à¦•à¦°à¦¾ à¦¯à¦¾à§Ÿà¦¨à¦¿à¥¤",
      apiError: "âŒ à¦¤à¦¥à§à¦¯ à¦†à¦¨à¦¤à§‡ à¦—à¦¿à¦¯à¦¼à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦¹à§Ÿà§‡à¦›à§‡à¥¤"
    }
  },

  onStart: async function ({ api, event, getLang }) {
    const { threadID, messageID, type, messageReply, body } = event;
    let question = "";
    const tempVoicePath = path.join(__dirname, "cache", `bard_voice_${Date.now()}.mp3`); // Unique file name

    // Determine input source
    if (type === "message_reply" && messageReply.attachments[0]?.type === "photo") {
      const imageURL = messageReply.attachments[0].url;
      question = await convertImageToText(imageURL);
      if (!question) return api.sendMessage(getLang("imgError"), threadID, messageID);
    } else {
      question = body.replace(/^.*?\s/, "").trim();
      if (!question) return api.sendMessage(getLang("noInput"), threadID, messageID);
    }

    // Notify user of processing
    api.sendMessage(getLang("processing"), threadID);

    try {
      // Fetch response from Bard AI
      const res = await axios.get(`https://bard-ai.arjhilbard.repl.co/bard?ask=${encodeURIComponent(question)}`);
      const respond = res.data.message;

      // Generate voice response
      const gttsInstance = new gtts(respond, "en"); // Future enhancement: Detect language or allow user choice
      gttsInstance.save(tempVoicePath, function (error) {
        if (error) {
          console.error("Voice generation error:", error);
          return api.sendMessage(getLang("voiceError"), threadID, messageID);
        }

        // Send text and voice response
        api.sendMessage(
          {
            body: `ğŸ¤– ğ—•ğ—®ğ—¿ğ—± ğ—”ğ—œ ğ—¥ğ—²ğ—½ğ—¹ğ˜†:\n\n${respond}`,
            attachment: fs.createReadStream(tempVoicePath)
          },
          threadID,
          () => fs.unlinkSync(tempVoicePath), // Clean up after sending
          messageID
        );
      });
    } catch (err) {
      console.error("API error:", err);
      api.sendMessage(getLang("apiError"), threadID, messageID);
    }
  }
};

async function convertImageToText(imageURL) {
  try {
    const response = await axios.get(`https://bard-ai.arjhilbard.repl.co/api/other/img2text?input=${encodeURIComponent(imageURL)}`);
    return response.data.extractedText;
  } catch (err) {
    console.error("Image-to-text error:", err);
    return null;
  }
}
