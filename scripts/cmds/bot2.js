const axios = require("axios");
const fs = require("fs-extra");
const gtts = require("gtts");
const path = require("path");

// ============================== â˜£ï¸ ATOMIC DESIGN SYSTEM â˜£ï¸ ============================== //
const design = {
  header: "âš¡ ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—•ğ—¢ğ—§ ğ—©ğŸ® âš¡",
  footer: "âœ¨ ğ—£ğ—¼ğ˜„ğ—²ğ—¿ğ—²ğ—± ğ—¯ğ˜† ğ—”ğ˜€ğ—¶ğ—³ ğ— ğ—®ğ—µğ—ºğ˜‚ğ—± ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—§ğ—²ğ—°ğ—µ âœ¨",
  separator: "â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°â–±â–°",
  emoji: {
    thinking: "âš›ï¸",
    success: "âœ…",
    error: "âš ï¸",
    voice: "ğŸ”Š",
    image: "ğŸ–¼ï¸",
    ai: "ğŸ¤–"
  }
};

const formatMessage = (content, type = "default") => {
  return `${design.header}\n${design.separator}\n${content}\n${design.separator}\n${design.footer}`;
};

const simulateTyping = (api, threadID, duration = 2000) => {
  api.sendTyping(threadID);
  return new Promise(resolve => setTimeout(resolve, duration));
};
// ======================================================================================== //

module.exports = {
  config: {
    name: "bot2",
    aliases: ["atomicbot", "ai2"],
    version: "3.0",
    usePrefix: true,
    hasPermission: 0,
    credits: "â˜£ğ€ğ“ğğŒğˆğ‚âš› ğ€ğ¬ğ¢ğŸ ğŒğšğ¡ğ¦ğ®ğ",
    description: "Atomic AI with OCR and voice response capabilities",
    commandCategory: "ai",
    usages: "{pn} <text | reply image>",
    cooldowns: 5
  },

  onStart: async function ({ api, event }) {
    const { threadID, messageID, type, messageReply, body } = event;
    const voicePath = path.join(__dirname, "cache", `atomic_voice_${Date.now()}.mp3`);
    
    try {
      // Start typing animation
      await simulateTyping(api, threadID);
      
      let question = "";
      let processingMessage = null;
      
      // Handle image reply
      if (type === "message_reply" && messageReply?.attachments?.[0]?.type === "photo") {
        processingMessage = await api.sendMessage(
          formatMessage(`${design.emoji.image} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—œğ— ğ—”ğ—šğ—˜ ğ—”ğ—¡ğ—”ğ—Ÿğ—¬ğ—¦ğ—œğ—¦\n\nâ–¸ Processing image content...`),
          threadID
        );
        
        const imageURL = messageReply.attachments[0].url;
        const imgToText = await axios.get(`https://bard-ai.arjhilbard.repl.co/api/other/img2text?input=${encodeURIComponent(imageURL)}`);
        question = imgToText.data.extractedText;
        
        if (!question) {
          const errorMsg = formatMessage(`${design.emoji.error} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—¢ğ—–ğ—¥ ğ—™ğ—”ğ—œğ—Ÿ\n\nâ–¸ Could not extract text from image`);
          return api.sendMessage(errorMsg, threadID, messageID);
        }
        
        await api.unsendMessage(processingMessage.messageID);
      } 
      // Handle text input
      else {
        question = body.replace(/^.*?\s/, "").trim();
        if (!question) {
          const guideMsg = formatMessage(`${design.emoji.error} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—œğ—¡ğ—£ğ—¨ğ—§\n\nâ–¸ Please provide text or reply to an image\nâ–¸ Example: ${this.config.name} explain quantum physics`);
          return api.sendMessage(guideMsg, threadID, messageID);
        }
      }
      
      // Show thinking message
      const thinkingMsg = await api.sendMessage(
        formatMessage(`${design.emoji.thinking} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—§ğ—›ğ—œğ—¡ğ—ğ—œğ—¡ğ—š\n\nâ–¸ Processing your request with atomic precision...`),
        threadID
      );
      
      // Get AI response
      const res = await axios.get(`https://bard-ai.arjhilbard.repl.co/bard?ask=${encodeURIComponent(question)}`);
      const reply = res.data.message;
      
      // Generate voice response
      const gttsVoice = new gtts(reply, 'en');
      await new Promise((resolve, reject) => {
        gttsVoice.save(voicePath, (err) => {
          if (err) reject(err);
          else resolve();
        });
      });
      
      // Prepare success response
      const successContent = `${design.emoji.ai} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—¥ğ—˜ğ—¦ğ—£ğ—¢ğ—¡ğ—¦ğ—˜\n\n${reply}\n\n${design.emoji.voice} Voice response attached`;
      const successMsg = formatMessage(successContent);
      
      // Send response with voice
      await api.unsendMessage(thinkingMsg.messageID);
      await api.sendMessage({
        body: successMsg,
        attachment: fs.createReadStream(voicePath)
      }, threadID);
      
      // Clean up voice file
      fs.unlinkSync(voicePath);
      
    } catch (err) {
      console.error("Atomic Bot Error:", err);
      
      const errorContent = `${design.emoji.error} ğ—”ğ—§ğ—¢ğ— ğ—œğ—– ğ—¦ğ—¬ğ—¦ğ—§ğ—˜ğ—  ğ—™ğ—”ğ—œğ—Ÿğ—¨ğ—¥ğ—˜\n\nâ–¸ ${err.message || "Error processing request"}\nâ–¸ Please try again later`;
      const errorMsg = formatMessage(errorContent);
      
      api.sendMessage(errorMsg, threadID, messageID);
      
      // Clean up voice file if exists
      if (fs.existsSync(voicePath)) {
        fs.unlinkSync(voicePath);
      }
    }
  }
};
